{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir dialogue_sample_voices\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1XSfK3NyMmtNiPcfELZmOlgvKslGuvJq2/view?usp=sharing\n",
        "!unzip sample_.zip -d \"/content/dialogue_sample_voices\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5wmL4sLRmLp",
        "outputId": "93799515-ec63-4783-8afc-066ad9b127f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XSfK3NyMmtNiPcfELZmOlgvKslGuvJq2\n",
            "To: /content/sample_.zip\n",
            "100% 13.4M/13.4M [00:00<00:00, 35.5MB/s]\n",
            "Archive:  sample_.zip\n",
            "  inflating: /content/dialogue_sample_voices/sample_1.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_2.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_3.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_4.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_5.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_6.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_7.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_8.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_9.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_10.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_11.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_12.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_13.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_14.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_15.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_16.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_17.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_18.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_19.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_20.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_21.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_22.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_23.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_24.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_25.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_26.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_27.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_28.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_29.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_30.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_31.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_32.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_33.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_34.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_35.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_36.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_37.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_38.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_39.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_40.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_41.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_42.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_43.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_44.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_45.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_46.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_47.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_48.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_49.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_50.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_51.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_52.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_53.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_54.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_55.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_56.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_57.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_58.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_59.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_60.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_61.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_62.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_63.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_64.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_65.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_66.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_67.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_68.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_69.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_70.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_71.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_72.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_73.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_74.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_75.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_76.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_77.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_78.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_79.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_80.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_81.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_82.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_83.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_84.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_85.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_86.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_87.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_88.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_89.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_90.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_91.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_92.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_93.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_94.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_95.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_96.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_97.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_98.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_99.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_100.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_101.wav  \n",
            "  inflating: /content/dialogue_sample_voices/sample_102.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5WzA5AkSFwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUYifKTfDJhR",
        "outputId": "deddc7f7-f29f-46c2-e8cc-b44b4df7a5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-mon6ctca/unsloth_e14eef14fbb8497198084bd9b5267b1b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-mon6ctca/unsloth_e14eef14fbb8497198084bd9b5267b1b\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit bfe38e6ea8d3d7cf8ce9e37962de03c71c90cbe2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting transformers>=4.43.2 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting sentencepiece>=0.2.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.5)\n",
            "Collecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.4)\n",
            "Collecting requests>=2.32.2 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.8-py3-none-any.whl size=136830 sha256=9f3f3bd336f8d2f5a7c485d522ab78fe73016580681ab89a869cfe0204d982d5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-79ebfmsd/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: sentencepiece, xxhash, unsloth, shtab, requests, pyarrow, hf-transfer, fsspec, dill, multiprocess, tyro, transformers, datasets\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 hf-transfer-0.1.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 sentencepiece-0.2.0 shtab-1.7.1 transformers-4.43.4 tyro-0.8.5 unsloth-2024.8 xxhash-3.4.1\n",
            "Collecting xformers<0.0.27\n",
            "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting trl<0.9.0\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, xformers, trl, peft\n",
            "Successfully installed bitsandbytes-0.43.3 peft-0.12.0 trl-0.8.6 xformers-0.0.26.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q speechbrain noisereduce pydub PersianG2p gradio persian_phonemizer datasets soundfile jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW22fw7dEAvM",
        "outputId": "a41d9649-d5d9-4318-a7a2-f5758d23cac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.1/928.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m920.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.12 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\n",
            "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.3.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHXQPsOZDF-2"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import librosa\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import SpeechT5HifiGan\n",
        "from transformers import AutoProcessor, AutoModelForTextToSpectrogram\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "import noisereduce as nr\n",
        "from pydub import AudioSegment\n",
        "from PersianG2p import Persian_g2p_converter\n",
        "from scipy.io import wavfile\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(1)\n",
        "\n",
        "##########              ##########\n",
        "#          Load Models\n",
        "##########             ##########\n",
        "\n",
        "########## Whisper\n",
        "model_directory = \"Timi2/whisper_medium_correct\"\n",
        "processor = WhisperProcessor.from_pretrained(model_directory, language=\"Persian\")\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(model_directory)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "whisper_model = whisper_model.to(device)\n",
        "\n",
        "tts_processor = AutoProcessor.from_pretrained(\"Alidr79/speecht5_v2_best\")\n",
        "tts_model = AutoModelForTextToSpectrogram.from_pretrained(\"Alidr79/speecht5_v2_best\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########              ##########\n",
        "#          TTS Model\n",
        "##########             ##########\n",
        "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
        "\n",
        "speaker_model = EncoderClassifier.from_hparams(\n",
        "    source=spk_model_name,\n",
        "    run_opts={\"device\": device},\n",
        "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
        ")\n",
        "\n",
        "def create_speaker_embedding(waveform):\n",
        "    with torch.no_grad():\n",
        "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
        "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
        "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
        "    return speaker_embeddings\n",
        "\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "PersianG2Pconverter = Persian_g2p_converter(use_large = True)\n",
        "\n",
        "def denoise_audio(audio, sr):\n",
        "    # Perform noise reduction\n",
        "    denoised_audio = nr.reduce_noise(y=audio, sr=sr)\n",
        "    return denoised_audio\n",
        "\n",
        "\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)\n",
        "\n",
        "\n",
        "def tts_function(slider_value, input_text):\n",
        "    audio_embedding,sample_rate_embedding = librosa.load(f'./dialogue_sample_voices/sample_{str(slider_value)}.wav')\n",
        "    if sample_rate_embedding!=16_000:\n",
        "        audio_embedding = librosa.resample(audio_embedding, orig_sr=sample_rate_embedding, target_sr=16_000)\n",
        "    # assert sample_rate_embedding == 16_000\n",
        "\n",
        "    len_audio = len(audio_embedding)/16_000\n",
        "\n",
        "    with torch.no_grad():\n",
        "        speaker_embedding = create_speaker_embedding(audio_embedding)\n",
        "        speaker_embedding = torch.tensor(speaker_embedding).unsqueeze(0)\n",
        "\n",
        "    phonemes = PersianG2Pconverter.transliterate(input_text, tidy = False, secret = True)\n",
        "\n",
        "    # text = \"</s>\"\n",
        "    # for i in phonemes.replace(' .', '').split(\" \"):\n",
        "    #     text += i + \" <pad> \"\n",
        "\n",
        "    # text += \"</s>\"\n",
        "\n",
        "    text = phonemes\n",
        "\n",
        "    print(\"sentence phonemes:\", text)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = tts_processor(text = text, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        spectrogram = tts_model.generate_speech(inputs[\"input_ids\"], speaker_embedding, minlenratio = 2, maxlenratio = 4, threshold = 0.3)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        speech = vocoder(spectrogram)\n",
        "\n",
        "    speech = speech.numpy().reshape(-1)\n",
        "    speech_denoised = denoise_audio(speech, 16000)\n",
        "    sf.write(\"in_speech.wav\", speech_denoised, 16000)\n",
        "\n",
        "    sound = AudioSegment.from_wav(\"in_speech.wav\", \"wav\")\n",
        "    normalized_sound = match_target_amplitude(sound, -20.0)\n",
        "    normalized_sound.export(\"out_sound.wav\", format=\"wav\")\n",
        "\n",
        "    sample_rate_out, audio_out = wavfile.read(\"out_sound.wav\")\n",
        "\n",
        "    assert sample_rate_out == 16_000\n",
        "\n",
        "    return 16000, (audio_out.reshape(-1)).astype(np.int16)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########              ##########\n",
        "#          LLAMA Model\n",
        "##########             ##########\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Timi2/best_model\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "\n",
        "# model.load_state_dict(torch.load(\"trained_llama3_on_persian_high_train.pt\"))\n",
        "\n",
        "\n",
        "##########              ##########\n",
        "#        PUT ALL TO GATHER\n",
        "######### + Gradio APP  ##########\n",
        "\n",
        "\n",
        "history = []\n",
        "def master_function(slider_value, user_voice):\n",
        "\n",
        "    # load model and processor\n",
        "\n",
        "    sr,audio = user_voice\n",
        "\n",
        "    audio = librosa.resample(audio.astype(np.float32) / 32768.0, orig_sr=sr, target_sr=16000)\n",
        "    # sf.write(\"output_path.wav\",audio, 16000)\n",
        "    # print(\"Audio saved\")\n",
        "    input_features = processor(torch.tensor(audio), sampling_rate=16000, return_tensors=\"pt\").input_features.cuda()\n",
        "\n",
        "    # generate token ids\n",
        "    predicted_ids = whisper_model.generate(input_features)\n",
        "    # decode token ids to text\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "    print(\"1. transcription: \", transcription)\n",
        "    # alpaca_prompt = Copied from above\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "    inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            transcription[0], # instruction\n",
        "            \"\", # input\n",
        "            \"\", # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
        "    llama_response = tokenizer.batch_decode(outputs)\n",
        "    llama_response = llama_response[0].split('Response')[-1].split('<|end_of_text|>')[0][2:]\n",
        "\n",
        "    if \".\" not in llama_response:\n",
        "        llama_response += \".\"\n",
        "    print(\"2. LLAMA response: \", llama_response)\n",
        "\n",
        "\n",
        "    all_speech = []\n",
        "    llama_response_list = llama_response.split(\".\")\n",
        "    print(llama_response_list)\n",
        "    for sentence in llama_response_list:\n",
        "        if sentence!=\"\\n\" and sentence!=\"\":\n",
        "            sampling_rate_response, audio_chunk_response = tts_function(slider_value, sentence)\n",
        "            all_speech.append(audio_chunk_response)\n",
        "\n",
        "    audio_response = np.concatenate(all_speech)\n",
        "    assert sampling_rate_response == 16_000\n",
        "    return sampling_rate_response, audio_response\n",
        "\n",
        "slider = gr.Slider(\n",
        "    minimum=1,\n",
        "    maximum=102,\n",
        "    value=8,\n",
        "    step=1,\n",
        "    label=\"Select a speaker\"\n",
        ")\n",
        "\n",
        "text_input = gr.Textbox(\n",
        "    label=\"Enter some text\",\n",
        "    placeholder=\"Type something here...\"\n",
        ")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn = master_function,\n",
        "    inputs=[slider, \"audio\"],  # List of inputs\n",
        "    outputs = \"audio\"\n",
        ")\n",
        "\n",
        "demo.queue().launch(root_path=\"/gradio-demo\", share = True)\n"
      ]
    }
  ]
}